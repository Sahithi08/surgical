{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport gc\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_folder = '/kaggle/input/surgical/11'\nvideo_files = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\nlabel_dict = {\n    'tool_video_o4.mp4': 'label1',\n}\nframes = []\nlabels = []\nfor video_file in video_files:\n    if video_file.split('/')[-1] in label_dict:\n        label = label_dict[video_file.split('/')[-1]]\n    else:\n        label = 'unknown'\n    text_file = video_file.replace('.mp4', '.txt')\n    with open(text_file, 'r') as f:\n        lines = f.readlines()\n    instruments = [line.strip() for line in lines]\n    cap = cv2.VideoCapture(video_file)\n\n    if not cap.isOpened():\n        print('Error opening video file:', video_file)\n    else:\n        while True:\n            ret, frame = cap.read()\n\n            if not ret:\n                break\n\n            frame = cv2.resize(frame, (224, 224))\n            frames.append(frame)\n\n            label_vec = np.zeros(2)\n            if label == 'label1':\n                label_vec[0] = 1\n            else:\n                label_vec[1] = 1\n                \n            instruments_array = np.zeros(7)\n#             for i in range(len(instruments)):\n            for i in range(len(instruments)):\n                if instruments[i] == 'grasper':\n                    instruments_array[i] = 0\n                elif instruments[i] == 'Bipolar':\n                    instruments_array[i] = 1\n                elif instruments[i] == 'hook':\n                    instruments_array[i] = 2\n                elif instruments[i] == 'scissors':\n                    instruments_array[i] = 3\n                elif instruments[i] == 'clipper':\n                    instruments_array[i] = 4\n                elif instruments[i] == 'irrigator':\n                    instruments_array[i] = 5\n                elif instruments[i] == 'specimenbag':\n                    instruments_array[i] = 6\n\n            \n            label_and_instruments = np.concatenate((label_vec, instruments_array))\n            labels.append(label_and_instruments)\n\n        cap.release()\n\ngc.collect()\nnum_frames = len(frames)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(frames)\ny_train = np.array(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=1./255,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cnn-1\nmodel = Sequential()\nmodel.add(Conv2D(2, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(Flatten())\n# model.add(Dense(2, activation='softmax'))\nmodel.add(Dense(9, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cnn-2\nmodel = Sequential()\nmodel.add(Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(9, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lenet\nmodel = Sequential()\nmodel.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(224, 224, 3)))\nmodel.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh'))\nmodel.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='tanh'))\nmodel.add(Dense(84, activation='tanh'))\nmodel.add(Dense(9, activation='softmax'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# zfnet\nmodel = Sequential()\nmodel.add(Conv2D(96, kernel_size=(7, 7), strides=(2, 2), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(5, 5), strides=(2, 2), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\nmodel.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(9, activation='softmax'))\n# model = Sequential()\n# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Flatten())\n# model.add(Dense(256, activation='relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(7, activation='softmax'))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# googlenet\nmodel = Sequential()\nmodel.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1000, activation='softmax'))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alexnet\nmodel = Sequential()\nmodel.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3), padding='valid'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VGG\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(224, 224, 3)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1000, activation='softmax'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# polynet\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Concatenate, GlobalAveragePooling2D, Dense\n\ndef conv_block(inputs, filters, kernel_size, strides=(1, 1), padding='same'):\n    x = Conv2D(filters, kernel_size, strides=strides, padding=padding, activation='relu')(inputs)\n    x = Conv2D(filters, kernel_size, strides=(1, 1), padding=padding, activation='relu')(x)\n    return x\n\ndef inception_block(inputs, filters):\n    # Path 1\n    x1 = conv_block(inputs, filters, (1, 1))\n\n    # Path 2\n    x2 = conv_block(inputs, filters, (1, 1))\n    x2 = conv_block(x2, filters, (3, 3))\n\n    # Path 3\n    x3 = conv_block(inputs, filters, (1, 1))\n    x3 = conv_block(x3, filters, (3, 3))\n    x3 = conv_block(x3, filters, (3, 3))\n\n    # Path 4\n    x4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n    x4 = conv_block(x4, filters, (1, 1))\n\n    # Concatenate paths\n    x = Concatenate()([x1, x2, x3, x4])\n    return x\n\ninputs = Input(shape=(224, 224, 3))\n\nx = conv_block(inputs, 32, (3, 3), strides=(2, 2))\nx = conv_block(x, 64, (3, 3))\nx = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\nx = inception_block(x, 32)\nx = inception_block(x, 64)\nx = inception_block(x, 128)\nx = inception_block(x, 256)\nx = inception_block(x, 512)\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\noutputs = Dense(1000, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\ngc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_data.flow(X_train, y_train, batch_size=2)\nhistory = model.fit(train_generator, steps_per_epoch=len(X_train)//2, epochs=5)\n# print('Training accuracy:', history.history['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_video_file = '/kaggle/input/surgical/train/tool_video_04.mp4'\ntest_text_file = '/kaggle/input/surgical/train/tool_video_04.txt'\ntest_frames = []\ntest_cap = cv2.VideoCapture(test_video_file)\nif not test_cap.isOpened():\n    print('Error opening test video file:', test_video_file)\nelse:\n    while True:\n        ret, frame = test_cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, (224, 224))\n        test_frames.append(frame)\n    test_cap.release()\n\nwith open(test_text_file, 'r') as f:\n    lines = f.readlines()\ntest_instruments = [line.strip() for line in lines]\n\ntest_frames = np.array(test_frames)\ntest_instruments_array = np.zeros(7)\n# for i in range(len(test_instruments)):\n#     if test_instruments[i] == 'grasper':\n#         test_instruments_array[0] = 1\n#     elif test_instruments[i] == 'Bipolar':\n#         test_instruments_array[1] = 1\n#     elif test_instruments[i] == 'hook':\n#         test_instruments_array[2] = 1\n#     elif test_instruments[i] == 'scissors':\n#         test_instruments_array[3] = 1\n#     elif test_instruments[i] == 'clipper':\n#         test_instruments_array[1] = 1\n#     elif test_instruments[i] == 'irrigator':\n#         test_instruments_array[1] = 1\n#     elif test_instruments[i] == 'specimenbag':\n#         test_instruments_array[1] = 1\nfor i in range(len(test_instruments)):\n        if test_instruments[i] == 'grasper':\n            test_instruments_array[i] = 0\n        elif test_instruments[i] == 'Bipolar':\n            test_instruments_array[i] = 1\n        elif test_instruments[i] == 'hook':\n            test_instruments_array[i] = 2\n        elif test_instruments[i] == 'scissors':\n            test_instruments_array[i] = 3\n        elif test_instruments[i] == 'clipper':\n            test_instruments_array[i] = 4\n        elif test_instruments[i] == 'irrigator':\n            test_instruments_array[i] = 5\n        elif test_instruments[i] == 'specimenbag':\n            test_instruments_array[i] = 6\n        \n\n\ntest_labels = np.tile(np.concatenate((np.zeros(1), test_instruments_array)), (len(test_frames), 1))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = model.predict(test_frames)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicted_labels = np.argmax(test_predictions[:, :2], axis=1)\n# true_labels = np.argmax(test_labels[:, :2], axis=1)\n# correct_predictions = np.sum(predicted_labels == true_labels)\n# total_predictions = len(true_labels)\n# accuracy = correct_predictions / total_predictions\n\n# print('Test accuracy:', accuracy*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_predictions = model.predict(test_frames)\npredicted_labels = np.argmax(test_predictions[:, :2], axis=1)\npredicted_instruments = np.argmax(test_predictions[:, 2:], axis=1) + 1  \ntrue_labels = np.argmax(test_labels[:, :2], axis=1)\ntrue_instruments = np.argmax(test_labels[:, 2:], axis=1) + 1  \n\ncorrect_predictions = np.sum(predicted_labels == true_labels) + np.sum(predicted_instruments == true_instruments)\ntotal_predictions = len(true_labels) + len(true_instruments)\naccuracy = correct_predictions / total_predictions\n\nprint('Test accuracy:', accuracy*100)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Compute the confusion matrix\nconf_matrix = confusion_matrix(true_instruments, predicted_instruments)\n\n# Calculate the accuracy for each instrument class\naccuracy = {}\nfor i in range(len(conf_matrix)):\n    accuracy[i+1] = conf_matrix[i][i] / sum(conf_matrix[i])\n    print(f'Accuracy for instrument class {i+1}: {accuracy[i+1]:.2f}')\n    \n    \nimport numpy as np\n\nunique_classes = np.unique(true_instruments)\nprint(unique_classes)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame(columns=['Video File', 'Instrument Prediction'])\n\nfor i in range(len(test_frames)):\n    video_file = test_video_file.split('/')[-1]\n    \n    # Extract the predicted instrument label\n    predicted_instrument = predicted_instruments[i]\n    \n    # Map the predicted label to its corresponding instrument name\n    if predicted_instrument == 1:\n        instrument_name = 'Bipolar'\n    elif predicted_instrument == 2:\n        instrument_name = 'Clipper'\n    elif predicted_instrument == 3:\n        instrument_name = 'Grasper'\n    elif predicted_instrument == 4:\n        instrument_name = 'Hook'\n    elif predicted_instrument == 5:\n        instrument_name = 'Irrigator'\n    elif predicted_instrument == 6:\n        instrument_name = 'Scissors'\n    elif predicted_instrument == 7:\n        instrument_name = 'Specimen Bag'\n    else:\n        instrument_name = 'Unknown'\n\n    df = df.append({'Video File': video_file, 'Instrument Prediction': instrument_name}, ignore_index=True)\ndf.to_excel('instrument_predictions.xlsx', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get a random frame and its corresponding predicted instrument\nidx = np.random.randint(0, len(test_frames))\nframe = test_frames[idx]\npredicted_instrument = predicted_instruments[idx]\n\ninstruments_dict = {\n    1: 'grasper',\n    2: 'Bipolar',\n    3: 'hook',\n    4: 'scissors',\n    5: 'clipper',\n    6: 'irrigator',\n    7: 'specimenbag'\n}\nif predicted_instrument in instruments_dict:\n    predicted_instrument_name = instruments_dict[predicted_instrument]\nelse:\n    predicted_instrument_name = 'unknown'\n\nfont = cv2.FONT_HERSHEY_SIMPLEX\norg = (50, 50)\nfontScale = 1\ncolor = (0, 255, 0)\nthickness = 2\nframe_with_text = cv2.putText(frame, predicted_instrument_name, org, font, fontScale, color, thickness, cv2.LINE_AA)\n\ncv2.imwrite('random_frame_with_predicted_instrument.jpg', frame_with_text)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}